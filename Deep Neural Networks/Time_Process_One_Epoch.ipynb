{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9734141e",
      "metadata": {
        "id": "9734141e"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "import shutil\n",
        "import torch,torchvision\n",
        "import math\n",
        "import pandas\n",
        "import natsort\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import datasets\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from PIL import Image, ImageFilter\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from itertools import cycle\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import torch\n",
        "from torchsummary import summary\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-gS5TFlAGVDD",
        "outputId": "ce2e1119-8fe2-4646-c2c5-f3dafa87390e"
      },
      "id": "-gS5TFlAGVDD",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/MyDrive/BinarySplit\""
      ],
      "metadata": {
        "id": "kpEw_1PbGhJI"
      },
      "id": "kpEw_1PbGhJI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = path\n",
        "class_dirs = os.listdir(path)"
      ],
      "metadata": {
        "id": "1D8JK2DZl46r"
      },
      "id": "1D8JK2DZl46r",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3fb92b8",
      "metadata": {
        "id": "d3fb92b8"
      },
      "outputs": [],
      "source": [
        "def load_data(path, test_split, val_split, batch_size, input_size):\n",
        "    modifyDict={'src':transforms.Compose([transforms.RandomHorizontalFlip(),\n",
        "                                              transforms.Resize((224,224)),\n",
        "                      transforms.RandomVerticalFlip(),\n",
        "                      transforms.RandomRotation(15),\n",
        "                      transforms.ToTensor(),\n",
        "                      transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])}\n",
        "    org_data = datasets.ImageFolder(root=path,transform =modifyDict['src'])\n",
        "    testSubsetSize=int(len(org_data)*test_split)\n",
        "    valDataSize=int(len(org_data)*val_split)\n",
        "    trainSubsetSize=len(org_data)-valDataSize-testSubsetSize\n",
        "    train_dataset,test_dataset,val_dataset = torch.utils.data.random_split(org_data,[trainSubsetSize,testSubsetSize,valDataSize])\n",
        "    trainSetDataLoader = DataLoader(train_dataset,batch_size,shuffle=True)\n",
        "    testSetDataLoader = DataLoader(test_dataset,batch_size,shuffle=False)\n",
        "    valSetDataLoader = DataLoader(val_dataset,batch_size,shuffle=False)\n",
        "    return trainSetDataLoader, testSetDataLoader, valSetDataLoader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader,test_loader,val_loader=load_data(path=path,\n",
        "                                              test_split=0.1,val_split= 0.1,batch_size=32, input_size=[224,224])"
      ],
      "metadata": {
        "id": "F-DC3GCskDtm"
      },
      "id": "F-DC3GCskDtm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "989a1afe",
      "metadata": {
        "id": "989a1afe"
      },
      "outputs": [],
      "source": [
        "model = torchvision.models.shufflenet_v2_x1_0(pretrained=False, num_classes=2)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "151f45f9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "151f45f9",
        "outputId": "75ca754b-4c32-4ce0-8609-ecec52ed1738"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time taken for each epoch:  86.22255325317383 seconds\n"
          ]
        }
      ],
      "source": [
        "S_time= time.time()\n",
        "for epoch in range(1):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "end_time = time.time()\n",
        "print(\"Time taken for each epoch: \", end_time - S_time, \"seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = torchvision.models.mobilenet_v2(pretrained=False, num_classes=2)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "3mg2vGnt29mC"
      },
      "id": "3mg2vGnt29mC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "S_time = time.time()\n",
        "for epoch in range(1):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "end_time = time.time()\n",
        "print(\"Time taken for each epoch: \", end_time - S_time, \"seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqmu7PtM3AL-",
        "outputId": "c0461295-0dd1-4de5-8a22-fc3dfe7e0868"
      },
      "id": "zqmu7PtM3AL-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time taken for each epoch:  80.56165027618408 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = torchvision.models.resnet18(pretrained=False, num_classes=2)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "CzV2e2Wd3ETA"
      },
      "id": "CzV2e2Wd3ETA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e74c317",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9e74c317",
        "outputId": "b5e871c6-f6f2-4aeb-aa1f-48fbb3770c96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time taken for each epoch:  69.78855347633362 seconds\n"
          ]
        }
      ],
      "source": [
        "S_time = time.time()\n",
        "for epoch in range(1):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "end_time = time.time()\n",
        "print(\"Time taken for each epoch: \", end_time - S_time, \"seconds\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}